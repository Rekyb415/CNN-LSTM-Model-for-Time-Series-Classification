{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import itertools\n",
        "import time\n",
        "import random\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import (CosineAnnealingLR,\n",
        "                                      CosineAnnealingWarmRestarts,\n",
        "                                      StepLR,\n",
        "                                      ExponentialLR)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, auc, f1_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "_WvJew37xetE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Now you can access files in your Google Drive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oiKaOn2xgWS",
        "outputId": "27b59ba5-07b0-40f1-9dd8-e0c94cb65877"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mitbih_test = pd.read_csv('/content/drive/MyDrive/ecg/mitbih_test.csv', header=None)\n",
        "mitbih_train = pd.read_csv('/content/drive/MyDrive/ecg/mitbih_train.csv', header=None)"
      ],
      "metadata": {
        "id": "VCk-rOloxi2O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mitbih_test.rename(columns={187: 'class'}, inplace=True)\n",
        "id_to_label = {\n",
        "    0: \"Normal\",\n",
        "    1: \"Artial Premature\",\n",
        "    2: \"Premature ventricular contraction\",\n",
        "    3: \"Fusion of ventricular and normal\",\n",
        "    4: \"Fusion of paced and normal\"\n",
        "}\n",
        "mitbih_test['label'] = mitbih_test.iloc[:, -1].map(id_to_label)\n"
      ],
      "metadata": {
        "id": "p-yEA_fsxkvJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mitbih_train.rename(columns={187: 'class'}, inplace=True)\n",
        "id_to_label = {\n",
        "    0: \"Normal\",\n",
        "    1: \"Artial Premature\",\n",
        "    2: \"Premature ventricular contraction\",\n",
        "    3: \"Fusion of ventricular and normal\",\n",
        "    4: \"Fusion of paced and normal\"\n",
        "}\n",
        "mitbih_train['label'] = mitbih_train.iloc[:, -1].map(id_to_label)\n"
      ],
      "metadata": {
        "id": "8l-vw8CyxlTm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mitbih_test.to_csv('mitbih_test_new.csv', index=False)\n",
        "mitbih_train.to_csv('mitbih_train_new.csv', index=False)"
      ],
      "metadata": {
        "id": "CkFYkIk1xotj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    csv_path = ''\n",
        "    seed = 2021\n",
        "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    train_csv_path = 'mitbih_train_new.csv'\n",
        "    test_csv_path = 'mitbih_test_new.csv'"
      ],
      "metadata": {
        "id": "i5cIaWjGxr9Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "ly1U2DnWxtan"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config()\n",
        "seed_everything(config.seed)"
      ],
      "metadata": {
        "id": "owRCQIX3xu56"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ECGDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.data_columns = self.df.columns[:-2].tolist()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        signal = self.df.loc[idx, self.data_columns].astype('float32')\n",
        "        signal = torch.FloatTensor([signal.values])\n",
        "        target = torch.LongTensor(np.array(self.df.loc[idx, 'class']))\n",
        "        return signal, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "metadata": {
        "id": "oz3TjabzxyxO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(phase: str, batch_size: int = 96) -> DataLoader:\n",
        "    '''\n",
        "    Dataset and DataLoader.\n",
        "    Parameters:\n",
        "        pahse: training or validation phase.\n",
        "        batch_size: data per iteration.\n",
        "    Returns:\n",
        "        data generator\n",
        "    '''\n",
        "    df = pd.read_csv(config.train_csv_path)\n",
        "    train_df, val_df = train_test_split(\n",
        "        df, test_size=0.15, random_state=config.seed, stratify=df['label']\n",
        "    )\n",
        "    train_df, val_df = train_df.reset_index(drop=True), val_df.reset_index(drop=True)\n",
        "    df = train_df if phase == 'train' else val_df\n",
        "    dataset = ECGDataset(df)\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size, num_workers=4)\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "fA5PlVuUx-wf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vh1FzQLxVjU",
        "outputId": "64834514-f7b8-4859-f69d-a92f71662096"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train mode | time: 15:59:07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/776 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 776/776 [03:55<00:00,  3.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 1.0160900411298197, accuracy: 0.9109623655913967, f1: 0.512061820943652, precision: 0.5259997922520085, recall: 0.9124008559795304\n",
            "val mode | time: 16:03:02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/137 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 137/137 [00:16<00:00,  8.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9829451082383885, accuracy: 0.9403810803167422, f1: 0.6168885061127378, precision: 0.6170944636464478, recall: 0.9361581928007615\n",
            "\n",
            "New checkpoint\n",
            "\n",
            "train mode | time: 16:03:19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/776 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 776/776 [03:57<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9629422598500406, accuracy: 0.9453682795698937, f1: 0.6332502010160292, precision: 0.6314744043248198, recall: 0.9556641435572446\n",
            "val mode | time: 16:07:17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/137 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 137/137 [00:16<00:00,  8.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9648529711891624, accuracy: 0.954874858597285, f1: 0.6492029617786615, precision: 0.6476272426860423, recall: 0.9667853804665567\n",
            "\n",
            "New checkpoint\n",
            "\n",
            "train mode | time: 16:07:33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/776 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 776/776 [03:58<00:00,  3.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9563253931076295, accuracy: 0.9515107526881722, f1: 0.6472223476553586, precision: 0.6461836905861901, recall: 0.9653100901546475\n",
            "val mode | time: 16:11:32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/137 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 137/137 [00:16<00:00,  8.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9603227854651564, accuracy: 0.9586279223227754, f1: 0.6564205122999177, precision: 0.6482972011092157, recall: 0.9809517756395036\n",
            "train mode | time: 16:11:49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/776 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 776/776 [04:02<00:00,  3.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9538436328980231, accuracy: 0.9536209677419357, f1: 0.652200571609294, precision: 0.6527467924704757, recall: 0.9672232228858396\n",
            "val mode | time: 16:15:52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/137 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 137/137 [00:16<00:00,  8.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9618870081270442, accuracy: 0.9567896870286577, f1: 0.654835938735793, precision: 0.6465616061038603, recall: 0.9788103196499778\n",
            "train mode | time: 16:16:09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/776 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 776/776 [03:58<00:00,  3.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.953130817720967, accuracy: 0.9544005376344088, f1: 0.6532010975431918, precision: 0.6549010044305441, recall: 0.9667955724268835\n",
            "val mode | time: 16:20:07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/137 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 137/137 [00:17<00:00,  8.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9578885628896601, accuracy: 0.960772530165913, f1: 0.6590026144352835, precision: 0.6579377698486781, recall: 0.9737994448319173\n",
            "train mode | time: 16:20:25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/776 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 776/776 [04:01<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9522833622655561, accuracy: 0.9551397849462357, f1: 0.6549007000959479, precision: 0.6561609944779161, recall: 0.9685714693512405\n",
            "val mode | time: 16:24:27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/137 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 137/137 [00:17<00:00,  7.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9569620056187406, accuracy: 0.9617093231523384, f1: 0.661717549121507, precision: 0.6636368050186325, recall: 0.9737185045113845\n",
            "\n",
            "New checkpoint\n",
            "\n",
            "train mode | time: 16:24:44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/776 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 776/776 [03:59<00:00,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9511857199668884, accuracy: 0.9559731182795701, f1: 0.6568436745298731, precision: 0.6591056959662202, recall: 0.969123141128493\n",
            "val mode | time: 16:28:44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/137 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 137/137 [00:17<00:00,  7.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9575060364954612, accuracy: 0.961326357466064, f1: 0.6598809191758357, precision: 0.6624832009341467, recall: 0.9709154619655473\n",
            "\n",
            "New checkpoint\n",
            "\n",
            "train mode | time: 16:29:02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/776 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 776/776 [04:00<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9502709817117261, accuracy: 0.9570483870967739, f1: 0.6592560457131474, precision: 0.6604158111021642, recall: 0.9720224752196631\n",
            "val mode | time: 16:33:02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/137 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 137/137 [00:17<00:00,  8.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9571015080984902, accuracy: 0.9613852752639519, f1: 0.6599744615642427, precision: 0.6621680536303107, recall: 0.9722163816165948\n",
            "train mode | time: 16:33:19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/776 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 776/776 [04:00<00:00,  3.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9496000436044508, accuracy: 0.9576935483870963, f1: 0.659696073556946, precision: 0.662290262578431, recall: 0.971181587889166\n",
            "val mode | time: 16:37:20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/137 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 137/137 [00:17<00:00,  7.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9565450119621614, accuracy: 0.962015695701358, f1: 0.6618577136960712, precision: 0.661464051949482, recall: 0.9761211229831893\n",
            "train mode | time: 16:37:37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/776 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 776/776 [03:59<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9492270828062488, accuracy: 0.9580564516129026, f1: 0.6599964724499399, precision: 0.662775345548293, recall: 0.9713139667685643\n",
            "val mode | time: 16:41:37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/137 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "<ipython-input-10-8280d9e6efbe>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  signal = torch.FloatTensor([signal.values])\n",
            "100%|██████████| 137/137 [00:16<00:00,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.9561561499448383, accuracy: 0.9623986613876324, f1: 0.6617581217848936, precision: 0.6635118807771425, recall: 0.9740671920629839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torchvision import models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.io import loadmat\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Swish activation function\n",
        "class Swish(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "# Convolutional, normalization, and pooling block\n",
        "class ConvNormPool(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, kernel_size, norm_type='batchnorm'):\n",
        "        super(ConvNormPool, self).__init__()\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.conv_1 = nn.Conv1d(in_channels=input_size, out_channels=hidden_size, kernel_size=kernel_size)\n",
        "        self.conv_2 = nn.Conv1d(in_channels=hidden_size, out_channels=hidden_size, kernel_size=kernel_size)\n",
        "        self.conv_3 = nn.Conv1d(in_channels=hidden_size, out_channels=hidden_size, kernel_size=kernel_size)\n",
        "        self.swish_1 = Swish()\n",
        "        self.swish_2 = Swish()\n",
        "        self.swish_3 = Swish()\n",
        "\n",
        "        if norm_type == 'group':\n",
        "            self.normalization_1 = nn.GroupNorm(num_groups=8, num_channels=hidden_size)\n",
        "            self.normalization_2 = nn.GroupNorm(num_groups=8, num_channels=hidden_size)\n",
        "            self.normalization_3 = nn.GroupNorm(num_groups=8, num_channels=hidden_size)\n",
        "        else:\n",
        "            self.normalization_1 = nn.BatchNorm1d(num_features=hidden_size)\n",
        "            self.normalization_2 = nn.BatchNorm1d(num_features=hidden_size)\n",
        "            self.normalization_3 = nn.BatchNorm1d(num_features=hidden_size)\n",
        "\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "    def forward(self, input):\n",
        "        conv1 = self.conv_1(input)\n",
        "        x = self.normalization_1(conv1)\n",
        "        x = self.swish_1(x)\n",
        "        x = nn.functional.pad(x, pad=(self.kernel_size - 1, 0))\n",
        "\n",
        "        x = self.conv_2(x)\n",
        "        x = self.normalization_2(x)\n",
        "        x = self.swish_2(x)\n",
        "        x = nn.functional.pad(x, pad=(self.kernel_size - 1, 0))\n",
        "\n",
        "        conv3 = self.conv_3(x)\n",
        "        x = self.normalization_3(conv1 + conv3)\n",
        "        x = self.swish_3(x)\n",
        "        x = nn.functional.pad(x, pad=(self.kernel_size - 1, 0))\n",
        "\n",
        "        x = self.pool(x)\n",
        "        return x\n",
        "\n",
        "# RNN module (LSTM or GRU)\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hid_size, num_rnn_layers=1, dropout_p=0.2, bidirectional=False, rnn_type='lstm'):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        if rnn_type == 'lstm':\n",
        "            self.rnn_layer = nn.LSTM(\n",
        "                input_size=input_size,\n",
        "                hidden_size=hid_size,\n",
        "                num_layers=num_rnn_layers,\n",
        "                dropout=dropout_p if num_rnn_layers > 1 else 0,\n",
        "                bidirectional=bidirectional,\n",
        "                batch_first=True,\n",
        "            )\n",
        "        else:\n",
        "            self.rnn_layer = nn.GRU(\n",
        "                input_size=input_size,\n",
        "                hidden_size=hid_size,\n",
        "                num_layers=num_rnn_layers,\n",
        "                dropout=dropout_p if num_rnn_layers > 1 else 0,\n",
        "                bidirectional=bidirectional,\n",
        "                batch_first=True,\n",
        "            )\n",
        "\n",
        "    def forward(self, input):\n",
        "        outputs, hidden_states = self.rnn_layer(input)\n",
        "        return outputs, hidden_states\n",
        "\n",
        "# Combined CNN+LSTM model\n",
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self, cnn_input_size, cnn_hid_size, rnn_hid_size, rnn_type, bidirectional, n_classes=5, kernel_size=5):\n",
        "        super(CNNLSTMModel, self).__init__()\n",
        "\n",
        "        self.rnn_layer = RNN(\n",
        "            input_size=cnn_hid_size * 2 if bidirectional else cnn_hid_size,\n",
        "            hid_size=rnn_hid_size,\n",
        "            rnn_type=rnn_type,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "        self.conv1 = ConvNormPool(\n",
        "            input_size=cnn_input_size,\n",
        "            hidden_size=cnn_hid_size,\n",
        "            kernel_size=kernel_size,\n",
        "        )\n",
        "        self.conv2 = ConvNormPool(\n",
        "            input_size=cnn_hid_size,\n",
        "            hidden_size=cnn_hid_size,\n",
        "            kernel_size=kernel_size,\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = nn.Linear(in_features=cnn_hid_size, out_features=n_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.conv1(input)\n",
        "        x = self.conv2(x)\n",
        "        x, _ = self.rnn_layer(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(-1, x.size(1) * x.size(2))\n",
        "        x = nn.functional.softmax(self.fc(x), dim=1)\n",
        "        return x\n",
        "\n",
        "# Meter class for tracking metrics\n",
        "class Meter:\n",
        "    def __init__(self, n_classes=5):\n",
        "        self.metrics = {}\n",
        "        self.confusion = torch.zeros((n_classes, n_classes))\n",
        "\n",
        "    def update(self, x, y, loss):\n",
        "        x = np.argmax(x.detach().cpu().numpy(), axis=1)\n",
        "        y = y.detach().cpu().numpy()\n",
        "        self.metrics['loss'] += loss\n",
        "        self.metrics['accuracy'] += accuracy_score(x, y)\n",
        "        self.metrics['f1'] += f1_score(x, y, average='macro')\n",
        "        self.metrics['precision'] += precision_score(x, y, average='macro', zero_division=1)\n",
        "        self.metrics['recall'] += recall_score(x, y, average='macro', zero_division=1)\n",
        "\n",
        "        self._compute_cm(x, y)\n",
        "\n",
        "    def _compute_cm(self, x, y):\n",
        "        for prob, target in zip(x, y):\n",
        "            if prob == target:\n",
        "                self.confusion[target][target] += 1\n",
        "            else:\n",
        "                self.confusion[target][prob] += 1\n",
        "\n",
        "    def init_metrics(self):\n",
        "        self.metrics['loss'] = 0\n",
        "        self.metrics['accuracy'] = 0\n",
        "        self.metrics['f1'] = 0\n",
        "        self.metrics['precision'] = 0\n",
        "        self.metrics['recall'] = 0\n",
        "\n",
        "    def get_metrics(self):\n",
        "        return self.metrics\n",
        "\n",
        "    def get_confusion_matrix(self):\n",
        "        return self.confusion\n",
        "\n",
        "# Trainer class\n",
        "class Trainer:\n",
        "    def __init__(self, net, lr, batch_size, num_epochs):\n",
        "        self.net = net.to(device)\n",
        "        self.num_epochs = num_epochs\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.AdamW(self.net.parameters(), lr=lr)\n",
        "        self.scheduler = CosineAnnealingLR(self.optimizer, T_max=num_epochs, eta_min=5e-6)\n",
        "        self.best_loss = float('inf')\n",
        "        self.phases = ['train', 'val']\n",
        "        self.dataloaders = {\n",
        "            phase: get_dataloader(phase, batch_size) for phase in self.phases\n",
        "        }\n",
        "        self.train_df_logs = pd.DataFrame()\n",
        "        self.val_df_logs = pd.DataFrame()\n",
        "\n",
        "    def _train_epoch(self, phase):\n",
        "        print(f\"{phase} mode | time: {time.strftime('%H:%M:%S')}\")\n",
        "\n",
        "        self.net.train() if phase == 'train' else self.net.eval()\n",
        "        meter = Meter()\n",
        "        meter.init_metrics()\n",
        "\n",
        "        for i, (data, target) in enumerate(tqdm(self.dataloaders[phase])):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = self.net(data)\n",
        "            loss = self.criterion(output, target)\n",
        "\n",
        "            if phase == 'train':\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "            meter.update(output, target, loss.item())\n",
        "\n",
        "        metrics = meter.get_metrics()\n",
        "        metrics = {k: v / i for k, v in metrics.items()}\n",
        "        df_logs = pd.DataFrame([metrics])\n",
        "        confusion_matrix = meter.get_confusion_matrix()\n",
        "\n",
        "        if phase == 'train':\n",
        "            self.train_df_logs = pd.concat([self.train_df_logs, df_logs], axis=0)\n",
        "        else:\n",
        "            self.val_df_logs = pd.concat([self.val_df_logs, df_logs], axis=0)\n",
        "\n",
        "        # show logs\n",
        "        print('{}: {}, {}: {}, {}: {}, {}: {}, {}: {}'\n",
        "              .format(*(x for kv in metrics.items() for x in kv)))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def run(self):\n",
        "        for epoch in range(self.num_epochs):\n",
        "            self._train_epoch(phase='train')\n",
        "            with torch.no_grad():\n",
        "                val_loss = self._train_epoch(phase='val')\n",
        "                self.scheduler.step()\n",
        "\n",
        "            if val_loss < self.best_loss:\n",
        "                self.best_loss = val_loss\n",
        "                print('\\nNew checkpoint\\n')\n",
        "                torch.save(self.net.state_dict(), f\"best_model_epoch{epoch}.pth\")\n",
        "\n",
        "model = CNNLSTMModel(1, 64, 64, 'lstm', True)\n",
        "trainer = Trainer(net=model, lr=1e-3, batch_size=96, num_epochs=10)\n",
        "trainer.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(config.test_csv_path)\n",
        "print(test_df.shape)\n",
        "test_dataset = ECGDataset(test_df)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=96, num_workers=0, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2cllEfiKz2b",
        "outputId": "7f2e5a40-ffe3-4256-c847-0f654e6faf36"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21892, 189)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "model.load_state_dict(torch.load(\"best_model_epoch7.pth\"))\n",
        "model.eval()\n",
        "model.to(device)\n",
        "predictions = []\n",
        "true_labels = []\n",
        "with torch.no_grad():\n",
        "    for data, labels in test_dataloader:\n",
        "        data = data.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predictions.extend(predicted.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "print(f\"Accuracy on the test set: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "72n0pQFrLZEe",
        "outputId": "39616249-7a1b-437c-e5e8-189a4826ebee"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n",
            "train mode | time: 19:33:42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-528991e7d075>\u001b[0m in \u001b[0;36m<cell line: 188>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEfficientNetLSTMModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mefficientnet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lstm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-69-528991e7d075>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-69-528991e7d075>\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, phase)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mmeter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from timm import create_model\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class EfficientNetModel(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(EfficientNetModel, self).__init__()\n",
        "        efficientnet_model = create_model('efficientnet_b7', pretrained=False)\n",
        "        self.features = efficientnet_model\n",
        "        in_features = efficientnet_model.num_features\n",
        "        self.classifier = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.mean([2, 3])  # Global average pooling\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# EfficientNet Trainer class\n",
        "class EfficientNetTrainer:\n",
        "    def __init__(self, net, lr, batch_size, num_epochs):\n",
        "        self.net = net.to(device)\n",
        "        self.num_epochs = num_epochs\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.AdamW(self.net.parameters(), lr=lr)\n",
        "        self.scheduler = CosineAnnealingLR(self.optimizer, T_max=num_epochs, eta_min=5e-6)\n",
        "        self.best_loss = float('inf')\n",
        "        self.phases = ['train', 'val']\n",
        "        self.dataloaders = {\n",
        "            phase: get_dataloader(phase, batch_size) for phase in self.phases\n",
        "        }\n",
        "        self.train_df_logs = pd.DataFrame()\n",
        "        self.val_df_logs = pd.DataFrame()\n",
        "\n",
        "    def _train_epoch(self, phase):\n",
        "        print(f\"{phase} mode | time: {time.strftime('%H:%M:%S')}\")\n",
        "\n",
        "        self.net.train() if phase == 'train' else self.net.eval()\n",
        "        meter = Meter()\n",
        "        meter.init_metrics()\n",
        "\n",
        "        for i, (data, target) in enumerate(tqdm(self.dataloaders[phase])):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = self.net(data)\n",
        "            loss = self.criterion(output, target)\n",
        "\n",
        "            if phase == 'train':\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "            meter.update(output, target, loss.item())\n",
        "\n",
        "        metrics = meter.get_metrics()\n",
        "        metrics = {k: v / i for k, v in metrics.items()}\n",
        "        df_logs = pd.DataFrame([metrics])\n",
        "        confusion_matrix = meter.get_confusion_matrix()\n",
        "\n",
        "        if phase == 'train':\n",
        "            self.train_df_logs = pd.concat([self.train_df_logs, df_logs], axis=0)\n",
        "        else:\n",
        "            self.val_df_logs = pd.concat([self.val_df_logs, df_logs], axis=0)\n",
        "\n",
        "        # show logs\n",
        "        print('{}: {}, {}: {}, {}: {}, {}: {}, {}: {}'\n",
        "              .format(*(x for kv in metrics.items() for x in kv)))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def run(self):\n",
        "        for epoch in range(self.num_epochs):\n",
        "            self._train_epoch(phase='train')\n",
        "            with torch.no_grad():\n",
        "                val_loss = self._train_epoch(phase='val')\n",
        "                self.scheduler.step()\n",
        "\n",
        "            if val_loss < self.best_loss:\n",
        "                self.best_loss = val_loss\n",
        "                print('\\nNew checkpoint\\n')\n",
        "                torch.save(self.net.state_dict(), f\"best_model_epoch{epoch}.pth\")\n",
        "\n",
        "\n",
        "# Usage\n",
        "efficientnet_model = EfficientNetModel(num_classes=5)\n",
        "efficientnet_trainer = EfficientNetTrainer(net=efficientnet_model, lr=1e-3, batch_size=96, num_epochs=10)\n",
        "efficientnet_trainer.run()\n"
      ],
      "metadata": {
        "id": "mAMCK_elRa82"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}